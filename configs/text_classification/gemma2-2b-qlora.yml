task: text_classification
base_model: google/gemma-2-2b
project_name: autotrain-gemma2-2b-qlora
log: tensorboard
backend: local

data:
  path: stanfordnlp/imdb
  train_split: train
  valid_split: test
  column_mapping:
    text_column: text
    target_column: label
params:
  max_seq_length: 1024
  epochs: 1
  batch_size: 16
  lr: 2e-5
  optimizer: adamw_torch
  scheduler: linear
  gradient_accumulation: 4
  peft: true
  quantization: int4
  target_modules: all-linear
  logging_steps: 1
  mixed_precision: bf16


hub:
  username: ${HF_USERNAME}
  token: ${HF_TOKEN}
  push_to_hub: true